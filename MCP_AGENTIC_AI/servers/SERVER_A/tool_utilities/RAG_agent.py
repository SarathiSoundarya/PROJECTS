from pydantic import BaseModel, Field
from typing import List
from models import azure_chatopenai_model, google_model
from logger.base_logger import get_logger
import os
import sys
from .RAG import retrieve_with_rerank
import traceback
from dotenv import load_dotenv
load_dotenv()
logger = get_logger(__name__)
AGENT_NAME = "rag_agent"


class RAGResponse(BaseModel):
    """Response model for RAG"""
    answer: str = Field(description="The answer to the user query gathered from the retrieved contents")
    doc_ids: List[str] = Field(description="List of retrived document ids that are relevant to the query and used to generate the answer")

def extract_ai_message(result: dict) -> str:
    """
    Extract AI message content from langchain agent result
    """
    messages = result.get("messages", [])

    for msg in reversed(messages):  # search from latest
        if msg.__class__.__name__ == "AIMessage":
            return msg.content

    return ""

def execute_rag_agent(user_query, topic, country, top_k=5):
    try:
        logger.info(f"Invoking {AGENT_NAME} with query: {user_query}")
        retrieved_docs = retrieve_with_rerank(user_query,None, country, top_k=int(top_k))
        logger.info(f"{AGENT_NAME} retrieved and reranked documents successfully. Number of documents retrieved: {len(retrieved_docs)}")
        #generate the response using the retrieved documents
        system_instructions = f"""
        You are a domain assistant answering questions using retrieved documents.

        INSTRUCTIONS:
        - Provide a short and precise answer (max 5 sentences).
        - Use only the information from the documents.
        - Do NOT repeat information.
        - If answer not found, say "I don't know".
        - Return document ids only for documents actually used.

        OUTPUT FORMAT (STRICT JSON):
        {{
        "answer": "...",
        "doc_ids": ["id1", "id2"]
        }}

        User Question:
        {user_query}

        Retrieved Documents:
        {str(retrieved_docs)}
        """

        structured_llm = google_model.with_structured_output(RAGResponse)
        result:RAGResponse = structured_llm.invoke(system_instructions)
        answer = result.answer
        doc_ids = result.doc_ids

        #extract the filenames from the doc ids
        #unique doc ids
        unique_doc_ids = set(doc_ids)
        filenames = list({
            doc["metadata"]["source"]
            for doc in retrieved_docs
            if doc["id"] in unique_doc_ids
        })
        filenames = ", ".join(filenames)

        final_response = f"Answer to the user query: {answer}\nDocument names used: {filenames}"
        logger.info(f"Final response generated by {AGENT_NAME}: {final_response}")
        return final_response
    
              
    except Exception as e:
        logger.error(f"Error in {AGENT_NAME} invoke method: {e}")
        logger.error(traceback.format_exc())
        return "Error executing RAG agent: " + str(e)
            
# if __name__ == "__main__":
#     #test the agent with a sample query
#     user_query = "What are the advisories for air pollution in India?"
#     topic = None
#     country = "india"
#     response = execute_rag_agent(user_query, country, top_k=5)
#     print(response)
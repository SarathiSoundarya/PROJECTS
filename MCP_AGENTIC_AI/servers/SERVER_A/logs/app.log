2026-02-20 23:01:30,381 - tool_utilities.plotting_agent - INFO - plotting_agent.py:18 - Invoking plotting_agent with query: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\4\environmental_data.csv, plot humidity and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\4
2026-02-20 23:01:30,386 - tool_utilities.plotting_agent - ERROR - plotting_agent.py:56 - Error in plotting_agent invoke method: 21 validation errors for SystemMessage
content.str
  Input should be a valid string [type=string_type, input_value=ChatPromptTemplate(input_... additional_kwargs={})]), input_type=ChatPromptTemplate]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].0.str
  Input should be a valid string [type=string_type, input_value=('name', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].0.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('name', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].1.str
  Input should be a valid string [type=string_type, input_value=('input_variables', ['sha..._folder', 'user_query']), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].1.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('input_variables', ['sha..._folder', 'user_query']), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].2.str
  Input should be a valid string [type=string_type, input_value=('optional_variables', []), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].2.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('optional_variables', []), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].3.str
  Input should be a valid string [type=string_type, input_value=('input_types', {}), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].3.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('input_types', {}), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].4.str
  Input should be a valid string [type=string_type, input_value=('output_parser', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].4.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('output_parser', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].5.str
  Input should be a valid string [type=string_type, input_value=('partial_variables', {}), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].5.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('partial_variables', {}), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].6.str
  Input should be a valid string [type=string_type, input_value=('metadata', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].6.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('metadata', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].7.str
  Input should be a valid string [type=string_type, input_value=('tags', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].7.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('tags', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].8.str
  Input should be a valid string [type=string_type, input_value=('messages', [SystemMessa... additional_kwargs={})]), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].8.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('messages', [SystemMessa... additional_kwargs={})]), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].9.str
  Input should be a valid string [type=string_type, input_value=('validate_template', False), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].9.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('validate_template', False), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
2026-02-20 23:01:30,395 - tool_utilities.data_analysis_agent - INFO - data_analysis_agent.py:18 - Invoking data_analysis_agent with query: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\4\environmental_data.csv, calculate average humidity and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\4
2026-02-20 23:01:30,397 - tool_utilities.data_analysis_agent - ERROR - data_analysis_agent.py:57 - Error in data_analysis_agent invoke method: 21 validation errors for SystemMessage
content.str
  Input should be a valid string [type=string_type, input_value=ChatPromptTemplate(input_... additional_kwargs={})]), input_type=ChatPromptTemplate]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].0.str
  Input should be a valid string [type=string_type, input_value=('name', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].0.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('name', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].1.str
  Input should be a valid string [type=string_type, input_value=('input_variables', ['sha..._folder', 'user_query']), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].1.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('input_variables', ['sha..._folder', 'user_query']), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].2.str
  Input should be a valid string [type=string_type, input_value=('optional_variables', []), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].2.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('optional_variables', []), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].3.str
  Input should be a valid string [type=string_type, input_value=('input_types', {}), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].3.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('input_types', {}), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].4.str
  Input should be a valid string [type=string_type, input_value=('output_parser', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].4.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('output_parser', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].5.str
  Input should be a valid string [type=string_type, input_value=('partial_variables', {}), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].5.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('partial_variables', {}), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].6.str
  Input should be a valid string [type=string_type, input_value=('metadata', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].6.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('metadata', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].7.str
  Input should be a valid string [type=string_type, input_value=('tags', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].7.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('tags', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].8.str
  Input should be a valid string [type=string_type, input_value=('messages', [SystemMessa... additional_kwargs={})]), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].8.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('messages', [SystemMessa... additional_kwargs={})]), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].9.str
  Input should be a valid string [type=string_type, input_value=('validate_template', False), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].9.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('validate_template', False), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
2026-02-21 11:24:11,633 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:227 - Load pretrained SentenceTransformer: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\models\all-MiniLM-L6-v2
2026-02-21 11:24:12,363 - sentence_transformers.cross_encoder.CrossEncoder - INFO - CrossEncoder.py:228 - Use pytorch device: cpu
2026-02-21 11:24:12,366 - __main__ - INFO - data_and_intelligence_server.py:28 - Embeedding and Reranker Models loaded successfully from local paths.
2026-02-21 11:24:12,437 - chromadb.telemetry.product.posthog - INFO - posthog.py:22 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-21 11:24:13,246 - __main__ - INFO - data_and_intelligence_server.py:36 - ChromaDB collection initialized successfully.
2026-02-21 11:30:17,232 - __main__ - INFO - data_and_intelligence_server.py:54 - Starting data visualization with query: Plot humidity from the environmental data for New york city from Jan 1 to Jan 31 2026. Save the plot to C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\5
2026-02-21 11:30:17,239 - tool_utilities.plotting_agent - INFO - plotting_agent.py:18 - Invoking plotting_agent with query: Plot humidity from the environmental data for New york city from Jan 1 to Jan 31 2026. Save the plot to C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\5 and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\5
2026-02-21 11:30:17,249 - tool_utilities.plotting_agent - ERROR - plotting_agent.py:56 - Error in plotting_agent invoke method: 21 validation errors for SystemMessage
content.str
  Input should be a valid string [type=string_type, input_value=ChatPromptTemplate(input_... additional_kwargs={})]), input_type=ChatPromptTemplate]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].0.str
  Input should be a valid string [type=string_type, input_value=('name', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].0.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('name', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].1.str
  Input should be a valid string [type=string_type, input_value=('input_variables', ['sha..._folder', 'user_query']), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].1.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('input_variables', ['sha..._folder', 'user_query']), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].2.str
  Input should be a valid string [type=string_type, input_value=('optional_variables', []), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].2.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('optional_variables', []), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].3.str
  Input should be a valid string [type=string_type, input_value=('input_types', {}), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].3.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('input_types', {}), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].4.str
  Input should be a valid string [type=string_type, input_value=('output_parser', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].4.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('output_parser', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].5.str
  Input should be a valid string [type=string_type, input_value=('partial_variables', {}), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].5.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('partial_variables', {}), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].6.str
  Input should be a valid string [type=string_type, input_value=('metadata', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].6.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('metadata', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].7.str
  Input should be a valid string [type=string_type, input_value=('tags', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].7.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('tags', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].8.str
  Input should be a valid string [type=string_type, input_value=('messages', [SystemMessa... additional_kwargs={})]), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].8.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('messages', [SystemMessa... additional_kwargs={})]), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].9.str
  Input should be a valid string [type=string_type, input_value=('validate_template', False), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].9.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('validate_template', False), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
2026-02-21 11:30:17,256 - __main__ - INFO - data_and_intelligence_server.py:56 - Data visualization completed.
2026-02-21 11:30:17,267 - __main__ - INFO - data_and_intelligence_server.py:44 - Starting data analysis with query: Calculate the average humidity from the environmental data for New york city from Jan 1 to Jan 31 2026. Save the analysis to C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\5
2026-02-21 11:30:17,267 - tool_utilities.data_analysis_agent - INFO - data_analysis_agent.py:18 - Invoking data_analysis_agent with query: Calculate the average humidity from the environmental data for New york city from Jan 1 to Jan 31 2026. Save the analysis to C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\5 and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\5
2026-02-21 11:30:17,272 - tool_utilities.data_analysis_agent - ERROR - data_analysis_agent.py:57 - Error in data_analysis_agent invoke method: 21 validation errors for SystemMessage
content.str
  Input should be a valid string [type=string_type, input_value=ChatPromptTemplate(input_... additional_kwargs={})]), input_type=ChatPromptTemplate]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].0.str
  Input should be a valid string [type=string_type, input_value=('name', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].0.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('name', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].1.str
  Input should be a valid string [type=string_type, input_value=('input_variables', ['sha..._folder', 'user_query']), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].1.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('input_variables', ['sha..._folder', 'user_query']), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].2.str
  Input should be a valid string [type=string_type, input_value=('optional_variables', []), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].2.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('optional_variables', []), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].3.str
  Input should be a valid string [type=string_type, input_value=('input_types', {}), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].3.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('input_types', {}), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].4.str
  Input should be a valid string [type=string_type, input_value=('output_parser', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].4.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('output_parser', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].5.str
  Input should be a valid string [type=string_type, input_value=('partial_variables', {}), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].5.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('partial_variables', {}), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].6.str
  Input should be a valid string [type=string_type, input_value=('metadata', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].6.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('metadata', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].7.str
  Input should be a valid string [type=string_type, input_value=('tags', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].7.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('tags', None), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].8.str
  Input should be a valid string [type=string_type, input_value=('messages', [SystemMessa... additional_kwargs={})]), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].8.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('messages', [SystemMessa... additional_kwargs={})]), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
content.list[union[str,dict[any,any]]].9.str
  Input should be a valid string [type=string_type, input_value=('validate_template', False), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/string_type
content.list[union[str,dict[any,any]]].9.dict[any,any]
  Input should be a valid dictionary [type=dict_type, input_value=('validate_template', False), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.12/v/dict_type
2026-02-21 11:30:17,272 - __main__ - INFO - data_and_intelligence_server.py:46 - Data analysis completed.
2026-02-21 12:05:37,905 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:227 - Load pretrained SentenceTransformer: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\models\all-MiniLM-L6-v2
2026-02-21 12:05:39,272 - sentence_transformers.cross_encoder.CrossEncoder - INFO - CrossEncoder.py:228 - Use pytorch device: cpu
2026-02-21 12:05:39,272 - __main__ - INFO - data_and_intelligence_server.py:28 - Embeedding and Reranker Models loaded successfully from local paths.
2026-02-21 12:05:39,371 - chromadb.telemetry.product.posthog - INFO - posthog.py:22 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-21 12:05:41,086 - __main__ - INFO - data_and_intelligence_server.py:36 - ChromaDB collection initialized successfully.
2026-02-21 12:07:13,296 - __main__ - INFO - data_and_intelligence_server.py:54 - Starting data visualization with query: plot the humidity over time
2026-02-21 12:07:13,299 - tool_utilities.plotting_agent - INFO - plotting_agent.py:18 - Invoking plotting_agent with query: plot the humidity over time and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\6
2026-02-21 12:07:13,316 - tool_utilities.plotting_agent - INFO - plotting_agent.py:43 - plotting_agent initialized!Starting execution...
2026-02-21 12:07:14,198 - tool_utilities.plotting_agent - INFO - plotting_agent.py:53 - plotting_agent execution completed. Results: {'messages': [HumanMessage(content='plot the humidity over time', additional_kwargs={}, response_metadata={}, id='242f59ee-0204-41fc-ae35-52b9f0154670'), AIMessage(content="I can plot the humidity over time for you. Could you please specify the CSV file you'd like me to use?", additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c7eea-a6f3-71a1-b4d7-b37b5b32e19b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 327, 'output_tokens': 25, 'total_tokens': 352, 'input_token_details': {'cache_read': 0}})]}
2026-02-21 12:07:14,198 - __main__ - INFO - data_and_intelligence_server.py:56 - Data visualization completed.
2026-02-21 12:10:34,128 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:227 - Load pretrained SentenceTransformer: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\models\all-MiniLM-L6-v2
2026-02-21 12:10:35,135 - sentence_transformers.cross_encoder.CrossEncoder - INFO - CrossEncoder.py:228 - Use pytorch device: cpu
2026-02-21 12:10:35,140 - __main__ - INFO - data_and_intelligence_server.py:28 - Embeedding and Reranker Models loaded successfully from local paths.
2026-02-21 12:10:35,351 - chromadb.telemetry.product.posthog - INFO - posthog.py:22 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-21 12:10:35,975 - __main__ - INFO - data_and_intelligence_server.py:36 - ChromaDB collection initialized successfully.
2026-02-21 12:45:46,104 - __main__ - INFO - data_and_intelligence_server.py:54 - Starting data visualization with User query: Plot humidity over time, CSV Path: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\9\environmental_data.csv, Shared Folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\9
2026-02-21 12:45:46,116 - tool_utilities.plotting_agent - INFO - plotting_agent.py:18 - Invoking plotting_agent with query: Plot humidity over time and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\9 and csv path: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\9\environmental_data.csv
2026-02-21 12:45:46,133 - tool_utilities.plotting_agent - INFO - plotting_agent.py:43 - plotting_agent initialized!Starting execution...
2026-02-21 12:45:47,259 - tool_utilities.plotting_agent - INFO - plotting_agent.py:53 - plotting_agent execution completed. Results: {'messages': [HumanMessage(content='Plot humidity over time', additional_kwargs={}, response_metadata={}, id='b3983890-10da-443f-bbcc-924e89e85edd'), AIMessage(content='I need a CSV file to plot humidity over time. Please provide the path to the CSV file.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c7f0d-f15e-70d0-86ab-e398775d6504-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 326, 'output_tokens': 20, 'total_tokens': 346, 'input_token_details': {'cache_read': 0}})]}
2026-02-21 12:45:47,259 - __main__ - INFO - data_and_intelligence_server.py:56 - Data visualization completed.
2026-02-21 14:11:12,436 - __main__ - INFO - data_and_intelligence_server.py:54 - Starting data visualization with User query: Plot humidity over time, CSV Path: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\10\environmental_data.csv, Shared Folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\10
2026-02-21 14:11:25,521 - __main__ - INFO - data_and_intelligence_server.py:56 - Data visualization completed.
2026-02-21 14:17:21,117 - __main__ - INFO - data_and_intelligence_server.py:54 - Starting data visualization with User query: Plot humidity data, CSV Path: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\10\environmental_data_new_york_city_2026-01-01_to_2026-01-31.csv, Shared Folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\10
2026-02-21 14:17:36,209 - __main__ - INFO - data_and_intelligence_server.py:56 - Data visualization completed.
2026-02-21 16:14:13,820 - __main__ - INFO - data_and_intelligence_server.py:54 - Starting data visualization with User query: plot humidity, CSV Filename: humidity.csv, Shared Folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\10
2026-02-21 16:14:13,828 - tool_utilities.plotting_agent - INFO - plotting_agent.py:36 - Invoking plotting_agent with query: plot humidity and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\10 and csv filename: humidity.csv
2026-02-21 16:14:13,844 - tool_utilities.plotting_agent - INFO - plotting_agent.py:57 - plotting_agent initialized! Starting execution...
2026-02-21 16:14:18,227 - tool_utilities.plotting_agent - INFO - plotting_agent.py:61 - plotting_agent execution completed. Results: 
2026-02-21 16:14:18,229 - __main__ - INFO - data_and_intelligence_server.py:56 - Data visualization completed.
2026-02-21 16:24:47,742 - __main__ - INFO - data_and_intelligence_server.py:54 - Starting data visualization with User query: plot the humdity, CSV Filename: new york city_2026-01-01_2026-01-31_31220e8d-7f95-4409-925e-c9a37c1cd69b.csv, Shared Folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\10
2026-02-21 16:24:47,742 - tool_utilities.plotting_agent - INFO - plotting_agent.py:36 - Invoking plotting_agent with query: plot the humdity and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\10 and csv filename: new york city_2026-01-01_2026-01-31_31220e8d-7f95-4409-925e-c9a37c1cd69b.csv
2026-02-21 16:24:47,756 - tool_utilities.plotting_agent - INFO - plotting_agent.py:57 - plotting_agent initialized! Starting execution...
2026-02-21 16:24:51,683 - tool_utilities.plotting_agent - INFO - plotting_agent.py:61 - plotting_agent execution completed. Results: 
2026-02-21 16:24:51,683 - __main__ - INFO - data_and_intelligence_server.py:56 - Data visualization completed.
2026-02-21 16:24:51,697 - __main__ - INFO - data_and_intelligence_server.py:54 - Starting data visualization with User query: plot the humidity from it, CSV Filename: new york city_2026-01-01_2026-01-10_d725287f-28a3-4f94-adda-b4b0149aa165.csv, Shared Folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\10
2026-02-21 16:24:51,700 - tool_utilities.plotting_agent - INFO - plotting_agent.py:36 - Invoking plotting_agent with query: plot the humidity from it and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\10 and csv filename: new york city_2026-01-01_2026-01-10_d725287f-28a3-4f94-adda-b4b0149aa165.csv
2026-02-21 16:24:51,708 - tool_utilities.plotting_agent - INFO - plotting_agent.py:57 - plotting_agent initialized! Starting execution...
2026-02-21 16:24:53,635 - tool_utilities.plotting_agent - INFO - plotting_agent.py:61 - plotting_agent execution completed. Results: 
2026-02-21 16:24:53,635 - __main__ - INFO - data_and_intelligence_server.py:56 - Data visualization completed.
2026-02-21 16:24:53,647 - __main__ - INFO - data_and_intelligence_server.py:54 - Starting data visualization with User query: plot the humidity from it, CSV Filename: new york city_2026-01-01_2026-01-10_7c8829ac-563d-49f0-9de9-488e65015bde.csv, Shared Folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\10
2026-02-21 16:24:53,647 - tool_utilities.plotting_agent - INFO - plotting_agent.py:36 - Invoking plotting_agent with query: plot the humidity from it and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\10\10 and csv filename: new york city_2026-01-01_2026-01-10_7c8829ac-563d-49f0-9de9-488e65015bde.csv
2026-02-21 16:24:53,660 - tool_utilities.plotting_agent - INFO - plotting_agent.py:57 - plotting_agent initialized! Starting execution...
2026-02-21 16:24:53,759 - google_genai._api_client - INFO - before_sleep.py:64 - Retrying google.genai._api_client.BaseApiClient._request_once in 1.69 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 6.354720131s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '6s'}]}}.
2026-02-21 16:24:55,552 - google_genai._api_client - INFO - before_sleep.py:64 - Retrying google.genai._api_client.BaseApiClient._request_once in 2.98 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 4.574861509s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '4s'}]}}.
2026-02-21 16:24:58,624 - google_genai._api_client - INFO - before_sleep.py:64 - Retrying google.genai._api_client.BaseApiClient._request_once in 4.29 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 1.493918974s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '1s'}]}}.
2026-02-21 16:25:02,975 - google_genai._api_client - INFO - before_sleep.py:64 - Retrying google.genai._api_client.BaseApiClient._request_once in 8.97 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 57.129259304s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}.
2026-02-21 16:25:12,151 - google_genai._api_client - INFO - before_sleep.py:64 - Retrying google.genai._api_client.BaseApiClient._request_once in 17 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 47.95865895s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '47s'}]}}.
2026-02-21 16:25:31,611 - __main__ - INFO - data_and_intelligence_server.py:56 - Data visualization completed.
2026-02-21 16:49:13,923 - __main__ - INFO - data_and_intelligence_server.py:54 - Starting data visualization with User query: Plot humidity data for New York city from Jan 11 to 15 2026, CSV Filename: new_york_environmental_data.csv, Shared Folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\11\1
2026-02-21 16:49:13,933 - tool_utilities.plotting_agent - INFO - plotting_agent.py:36 - Invoking plotting_agent with query: Plot humidity data for New York city from Jan 11 to 15 2026 and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\11\1 and csv filename: new_york_environmental_data.csv
2026-02-21 16:49:13,942 - tool_utilities.plotting_agent - INFO - plotting_agent.py:57 - plotting_agent initialized! Starting execution...
2026-02-21 16:49:16,378 - google_genai._api_client - INFO - before_sleep.py:64 - Retrying google.genai._api_client.BaseApiClient._request_once in 1.28 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 43.729285337s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '43s'}]}}.
2026-02-21 16:49:17,737 - google_genai._api_client - INFO - before_sleep.py:64 - Retrying google.genai._api_client.BaseApiClient._request_once in 2.2 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 42.341210385s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}.
2026-02-21 16:49:20,036 - google_genai._api_client - INFO - before_sleep.py:64 - Retrying google.genai._api_client.BaseApiClient._request_once in 4.89 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 40.047951399s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '40s'}]}}.
2026-02-21 16:49:25,026 - google_genai._api_client - INFO - before_sleep.py:64 - Retrying google.genai._api_client.BaseApiClient._request_once in 8.58 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 35.063630033s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '35s'}]}}.
2026-02-21 16:49:34,045 - google_genai._api_client - INFO - before_sleep.py:64 - Retrying google.genai._api_client.BaseApiClient._request_once in 16.5 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 26.042621514s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}.
2026-02-21 16:49:50,805 - __main__ - INFO - data_and_intelligence_server.py:56 - Data visualization completed.
2026-02-21 22:16:05,545 - __main__ - INFO - data_and_intelligence_server.py:54 - Starting data visualization with User query: Create a plot for temperature and humidity over time for New York City from 11th Jan to 12th Jan 2023., CSV Filename: New York City_2023-01-11_2023-01-12_51702777-e95d-4f52-a4d1-4b9c2a50eba7.csv, Shared Folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\12\6
2026-02-21 22:16:05,545 - tool_utilities.plotting_agent - INFO - plotting_agent.py:27 - Invoking plotting_agent with query: Create a plot for temperature and humidity over time for New York City from 11th Jan to 12th Jan 2023. and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\12\6 and csv filename: New York City_2023-01-11_2023-01-12_51702777-e95d-4f52-a4d1-4b9c2a50eba7.csv
2026-02-21 22:16:05,561 - tool_utilities.plotting_agent - INFO - plotting_agent.py:81 - plotting_agent initialized! Starting execution...
2026-02-21 22:16:18,049 - tool_utilities.plotting_agent - INFO - plotting_agent.py:85 - plotting_agent execution completed. Results: 97803454-737f-466e-a4e7-75e34f8a2359_plotly_json.json
2026-02-21 22:16:18,054 - __main__ - INFO - data_and_intelligence_server.py:56 - Data visualization completed.
2026-02-21 22:47:47,355 - __main__ - INFO - data_and_intelligence_server.py:54 - Starting data visualization with User query: plot the environmental data for New York City from 11th Jan to 12th Jan, CSV Filename: New York City_2023-01-11_2023-01-12_cc0d4ef6-aca8-470a-9f61-0bd5f7bb0628.csv, Shared Folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\12\7
2026-02-21 22:47:47,355 - tool_utilities.plotting_agent - INFO - plotting_agent.py:27 - Invoking plotting_agent with query: plot the environmental data for New York City from 11th Jan to 12th Jan and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\12\7 and csv filename: New York City_2023-01-11_2023-01-12_cc0d4ef6-aca8-470a-9f61-0bd5f7bb0628.csv
2026-02-21 22:47:47,370 - tool_utilities.plotting_agent - INFO - plotting_agent.py:82 - plotting_agent initialized! Starting execution...
2026-02-21 22:47:53,473 - tool_utilities.plotting_agent - INFO - plotting_agent.py:86 - plotting_agent execution completed. Results: 3778043f-a4e5-4ebb-b940-898fae16c0ae_plotly_json.json
2026-02-21 22:47:53,474 - __main__ - INFO - data_and_intelligence_server.py:56 - Data visualization completed.
2026-02-21 22:51:46,125 - __main__ - INFO - data_and_intelligence_server.py:54 - Starting data visualization with User query: Create plots for temperature, humidity, PM10, and PM2.5 levels for New York City from 11th Jan to 12th Jan., CSV Filename: New York City_2023-01-11_2023-01-12_387cf9eb-c5c9-4df8-a040-0df07b226fb3.csv, Shared Folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\12\8
2026-02-21 22:51:46,125 - tool_utilities.plotting_agent - INFO - plotting_agent.py:27 - Invoking plotting_agent with query: Create plots for temperature, humidity, PM10, and PM2.5 levels for New York City from 11th Jan to 12th Jan. and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\12\8 and csv filename: New York City_2023-01-11_2023-01-12_387cf9eb-c5c9-4df8-a040-0df07b226fb3.csv
2026-02-21 22:51:46,125 - tool_utilities.plotting_agent - INFO - plotting_agent.py:82 - plotting_agent initialized! Starting execution...
2026-02-21 22:51:56,364 - tool_utilities.plotting_agent - INFO - plotting_agent.py:86 - plotting_agent execution completed. Results: b9d0f1f8-afc0-4e57-94d4-ff9a43c65947_temperature_plotly_json.json
2026-02-21 22:51:56,364 - __main__ - INFO - data_and_intelligence_server.py:56 - Data visualization completed.
2026-02-22 10:35:17,763 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:227 - Load pretrained SentenceTransformer: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\models\all-MiniLM-L6-v2
2026-02-22 10:35:18,918 - sentence_transformers.cross_encoder.CrossEncoder - INFO - CrossEncoder.py:228 - Use pytorch device: cpu
2026-02-22 10:35:19,038 - chromadb.telemetry.product.posthog - INFO - posthog.py:22 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-22 10:44:22,053 - __main__ - INFO - data_and_intelligence_server.py:27 - Starting data visualization with User query: Plot the humidity data from the environmental data of New York City., CSV Filename: New York City_2026-01-01_2026-01-10_2fb5ed80-ca3f-4da8-a077-dcf1559d28eb.csv, Shared Folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\13\1
2026-02-22 10:44:22,057 - tool_utilities.plotting_agent - INFO - plotting_agent.py:27 - Invoking plotting_agent with query: Plot the humidity data from the environmental data of New York City. and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\13\1 and csv filename: New York City_2026-01-01_2026-01-10_2fb5ed80-ca3f-4da8-a077-dcf1559d28eb.csv
2026-02-22 10:44:22,070 - tool_utilities.plotting_agent - INFO - plotting_agent.py:82 - plotting_agent initialized! Starting execution...
2026-02-22 10:44:30,506 - tool_utilities.plotting_agent - INFO - plotting_agent.py:86 - plotting_agent execution completed. Results: c7e0f6b1-e711-4ed2-8313-fb4e5ce9f5d3_plotly_json.json
2026-02-22 10:44:30,506 - __main__ - INFO - data_and_intelligence_server.py:29 - Data visualization completed.
2026-02-22 10:56:29,966 - __main__ - INFO - data_and_intelligence_server.py:17 - Starting data analysis with query: Analyze the humidity data to find the mean, median, and percentiles of humidity.
2026-02-22 11:12:08,490 - __main__ - INFO - data_and_intelligence_server.py:37 - Starting RAG tool with query: advisories for air pollution in India, topic: pollution, country: india
2026-02-22 11:12:08,490 - tool_utilities.RAG_agent - INFO - RAG_agent.py:33 - Invoking rag_agent with query: advisories for air pollution in India
2026-02-22 11:12:09,369 - tool_utilities.RAG_agent - INFO - RAG_agent.py:35 - Retrieved documents: []
2026-02-22 11:12:09,369 - tool_utilities.RAG_agent - INFO - RAG_agent.py:36 - rag_agent retrieved and reranked documents successfully. Number of documents retrieved: 0
2026-02-22 11:12:11,822 - tool_utilities.RAG_agent - INFO - RAG_agent.py:62 - rag_agent generated answer successfully. Answer: I'm sorry, I don't have the information to answer that question based on the retrieved documents provided., Document names used: 
2026-02-22 11:12:11,827 - __main__ - INFO - data_and_intelligence_server.py:39 - RAG tool execution completed.
2026-02-22 11:12:24,590 - backoff - INFO - _common.py:105 - Backing off send_request(...) for 0.5s (requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Read timed out. (read timeout=15))
2026-02-22 13:48:39,041 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:227 - Load pretrained SentenceTransformer: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\models\all-MiniLM-L6-v2
2026-02-22 13:48:39,980 - sentence_transformers.cross_encoder.CrossEncoder - INFO - CrossEncoder.py:228 - Use pytorch device: cpu
2026-02-22 13:48:40,187 - chromadb.telemetry.product.posthog - INFO - posthog.py:22 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-22 13:50:53,656 - __main__ - INFO - data_and_intelligence_server.py:37 - Starting RAG tool with query: air pollution advisories, topic: pollution, country: india
2026-02-22 13:50:53,658 - tool_utilities.RAG_agent - INFO - RAG_agent.py:33 - Invoking rag_agent with query: air pollution advisories
2026-02-22 13:50:55,156 - tool_utilities.RAG_agent - ERROR - RAG_agent.py:81 - Error in rag_agent invoke method: slice indices must be integers or None or have an __index__ method
2026-02-22 13:50:55,156 - __main__ - INFO - data_and_intelligence_server.py:39 - RAG tool execution completed.
2026-02-22 13:57:59,691 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:227 - Load pretrained SentenceTransformer: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\models\all-MiniLM-L6-v2
2026-02-22 13:58:00,011 - sentence_transformers.cross_encoder.CrossEncoder - INFO - CrossEncoder.py:228 - Use pytorch device: cpu
2026-02-22 13:58:00,087 - chromadb.telemetry.product.posthog - INFO - posthog.py:22 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-22 13:59:32,297 - __main__ - INFO - data_and_intelligence_server.py:37 - Starting RAG tool with query: air pollution advisories, topic: pollution, country: india
2026-02-22 13:59:32,308 - tool_utilities.RAG_agent - INFO - RAG_agent.py:34 - Invoking rag_agent with query: air pollution advisories
2026-02-22 13:59:32,308 - tool_utilities.RAG_agent - ERROR - RAG_agent.py:82 - Error in rag_agent invoke method: invalid literal for int() with base 10: 'india'
2026-02-22 13:59:32,308 - tool_utilities.RAG_agent - ERROR - RAG_agent.py:83 - Traceback (most recent call last):
  File "C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\RAG_agent.py", line 35, in execute_rag_agent
    retrieved_docs = retrieve_with_rerank(user_query,None, country, top_k=int(top_k))
                                                                          ^^^^^^^^^^
ValueError: invalid literal for int() with base 10: 'india'

2026-02-22 13:59:32,308 - __main__ - INFO - data_and_intelligence_server.py:39 - RAG tool execution completed.
2026-02-22 14:03:41,203 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:227 - Load pretrained SentenceTransformer: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\models\all-MiniLM-L6-v2
2026-02-22 14:03:41,954 - sentence_transformers.cross_encoder.CrossEncoder - INFO - CrossEncoder.py:228 - Use pytorch device: cpu
2026-02-22 14:03:42,008 - chromadb.telemetry.product.posthog - INFO - posthog.py:22 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-22 14:05:16,887 - __main__ - INFO - data_and_intelligence_server.py:37 - Starting RAG tool with query: air pollution advisories in India, topic: pollution, country: india
2026-02-22 14:05:16,889 - tool_utilities.RAG_agent - INFO - RAG_agent.py:34 - Invoking rag_agent with query: air pollution advisories in India
2026-02-22 14:05:21,078 - tool_utilities.RAG_agent - INFO - RAG_agent.py:36 - rag_agent retrieved and reranked documents successfully. Number of documents retrieved: 5
2026-02-22 14:05:27,872 - tool_utilities.RAG_agent - INFO - RAG_agent.py:77 - Final response generated by rag_agent: Answer to the user query: Air pollution advisories in India are managed through the Air Quality Early Warning System (AQEWS), implemented by the Ministry of Earth Sciences, the India Meteorological Department, and the Indian Institute of Tropical Meteorology. This high-resolution system provides forecasts specifically for the Delhi-NCR region and major Indian cities, converting data into the Air Quality Index (AQI) to issue appropriate health advisories based on pollution severity. The Comprehensive Health Advisory on Air Pollution, updated under the National Programme on Climate Change and Human Health (NPCCHH), provides guidelines and action points for managing high AQI levels, emphasizing the role of state health authorities and nodal officers in monitoring air quality data.
Document names used: India_Health_Advisory_Air_Pollution.pdf
2026-02-22 14:05:27,872 - __main__ - INFO - data_and_intelligence_server.py:39 - RAG tool execution completed.
2026-02-22 14:11:27,312 - __main__ - INFO - data_and_intelligence_server.py:37 - Starting RAG tool with query: air pollution advisories, topic: pollution, country: india
2026-02-22 14:11:27,312 - tool_utilities.RAG_agent - INFO - RAG_agent.py:34 - Invoking rag_agent with query: air pollution advisories
2026-02-22 14:11:28,694 - tool_utilities.RAG_agent - INFO - RAG_agent.py:36 - rag_agent retrieved and reranked documents successfully. Number of documents retrieved: 5
2026-02-22 14:11:34,623 - tool_utilities.RAG_agent - INFO - RAG_agent.py:77 - Final response generated by rag_agent: Answer to the user query: The health advisory on air pollution, updated in 2023 by the National Programme on Climate Change & Human Health under India's Ministry of Health and Family Welfare, provides guidelines for health departments and officials. It includes recommendations during times of high Air Quality Index (AQI) levels and endorses the Central Pollution Control Board's (CPCB) Graded Response Action Plans for Delhi NCR. The document also highlights the impact of air pollution on vulnerable groups, offering tailored advice for program officials on how to manage air quality issues effectively. Social media message templates and relevant references are also provided to support public awareness efforts. 

Document names used: India_Health_Advisory_Air_Pollution.pdf
2026-02-22 14:11:34,623 - __main__ - INFO - data_and_intelligence_server.py:39 - RAG tool execution completed.
2026-02-22 14:15:45,107 - __main__ - INFO - data_and_intelligence_server.py:37 - Starting RAG tool with query: advisories for air pollution, topic: pollution, country: india
2026-02-22 14:15:45,108 - tool_utilities.RAG_agent - INFO - RAG_agent.py:34 - Invoking rag_agent with query: advisories for air pollution
2026-02-22 14:15:46,387 - tool_utilities.RAG_agent - INFO - RAG_agent.py:36 - rag_agent retrieved and reranked documents successfully. Number of documents retrieved: 5
2026-02-22 14:15:49,859 - tool_utilities.RAG_agent - INFO - RAG_agent.py:77 - Final response generated by rag_agent: Answer to the user query: The health advisory on air pollution focuses on recommendations for vulnerable populations, considerations during high Air Quality Index (AQI) levels, and measures to reduce household and outdoor exposure. It highlights the need for cross-ventilation in cooking areas and advises against burning mosquito coils indoors. The document also includes CPCB's Graded Response Plans for air quality management and emphasizes avoiding high traffic areas to minimize exposure. Social media templates on air pollution health messages are also provided for outreach initiatives.
Document names used: India_Health_Advisory_Air_Pollution.pdf
2026-02-22 14:15:49,859 - __main__ - INFO - data_and_intelligence_server.py:39 - RAG tool execution completed.
2026-02-22 14:42:41,304 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:227 - Load pretrained SentenceTransformer: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\models\all-MiniLM-L6-v2
2026-02-22 14:42:42,004 - sentence_transformers.cross_encoder.CrossEncoder - INFO - CrossEncoder.py:228 - Use pytorch device: cpu
2026-02-22 14:42:42,085 - chromadb.telemetry.product.posthog - INFO - posthog.py:22 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-22 14:58:36,373 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:227 - Load pretrained SentenceTransformer: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\models\all-MiniLM-L6-v2
2026-02-22 14:58:39,071 - sentence_transformers.cross_encoder.CrossEncoder - INFO - CrossEncoder.py:228 - Use pytorch device: cpu
2026-02-22 14:58:39,244 - chromadb.telemetry.product.posthog - INFO - posthog.py:22 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-22 15:19:42,493 - __main__ - INFO - data_and_intelligence_server.py:27 - Starting data visualization with User query: Plot humidity, CSV Filename: environmental_data.csv, Shared Folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\17\1
2026-02-22 15:19:42,504 - tool_utilities.plotting_agent - INFO - plotting_agent.py:27 - Invoking plotting_agent with query: Plot humidity and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\17\1 and csv filename: environmental_data.csv
2026-02-22 15:19:42,513 - tool_utilities.plotting_agent - ERROR - plotting_agent.py:44 - CSV file environmental_data.csv not found in shared folder or its parent directory.
2026-02-22 15:19:42,520 - __main__ - INFO - data_and_intelligence_server.py:29 - Data visualization completed.
2026-02-22 15:32:23,238 - __main__ - INFO - data_and_intelligence_server.py:27 - Starting data visualization with User query: Plot humidity, CSV Filename: environmental_data_New_York_City_2026-01-11_to_2026-01-17.csv, Shared Folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\18\1
2026-02-22 15:32:23,243 - tool_utilities.plotting_agent - INFO - plotting_agent.py:27 - Invoking plotting_agent with query: Plot humidity and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\18\1 and csv filename: environmental_data_New_York_City_2026-01-11_to_2026-01-17.csv
2026-02-22 15:32:23,251 - tool_utilities.plotting_agent - ERROR - plotting_agent.py:44 - CSV file environmental_data_New_York_City_2026-01-11_to_2026-01-17.csv not found in shared folder or its parent directory.
2026-02-22 15:32:23,251 - __main__ - INFO - data_and_intelligence_server.py:29 - Data visualization completed.
2026-02-22 15:37:46,642 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:227 - Load pretrained SentenceTransformer: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\models\all-MiniLM-L6-v2
2026-02-22 15:37:47,470 - sentence_transformers.cross_encoder.CrossEncoder - INFO - CrossEncoder.py:228 - Use pytorch device: cpu
2026-02-22 15:37:47,545 - chromadb.telemetry.product.posthog - INFO - posthog.py:22 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-22 15:41:05,890 - __main__ - INFO - data_and_intelligence_server.py:27 - Starting data visualization with User query: plot the humidity, CSV Filename: New York City_2026-01-11_2026-01-17_762e9531-2dc0-45e6-b056-57351959f70a.csv, Shared Folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\19\1
2026-02-22 15:41:05,904 - tool_utilities.plotting_agent - INFO - plotting_agent.py:27 - Invoking plotting_agent with query: plot the humidity and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\19\1 and csv filename: New York City_2026-01-11_2026-01-17_762e9531-2dc0-45e6-b056-57351959f70a.csv
2026-02-22 15:41:05,941 - tool_utilities.plotting_agent - INFO - plotting_agent.py:110 - plotting_agent initialized! Starting execution...
2026-02-22 15:41:11,963 - tool_utilities.plotting_agent - INFO - plotting_agent.py:114 - plotting_agent execution completed. Results: 224e2bac-19e7-4381-8482-838ca61878c5_plotly_json.json
2026-02-22 15:41:11,966 - __main__ - INFO - data_and_intelligence_server.py:29 - Data visualization completed.
2026-02-22 15:42:35,414 - __main__ - INFO - data_and_intelligence_server.py:37 - Starting RAG tool with query: List the advisories issued by Indian government for air pollution., topic: pollution, country: india
2026-02-22 15:42:35,416 - tool_utilities.RAG_agent - INFO - RAG_agent.py:34 - Invoking rag_agent with query: List the advisories issued by Indian government for air pollution.
2026-02-22 15:42:42,381 - tool_utilities.RAG_agent - INFO - RAG_agent.py:36 - rag_agent retrieved and reranked documents successfully. Number of documents retrieved: 5
2026-02-22 15:42:42,391 - google_genai.models - INFO - models.py:5466 - AFC is enabled with max remote calls: 10.
2026-02-22 15:42:44,063 - tool_utilities.RAG_agent - INFO - RAG_agent.py:77 - Final response generated by rag_agent: Answer to the user query: The Indian government has established an Air Quality Early Warning System (AQEWS) for India, which provides air quality forecasts in terms of the Air Quality Index (AQI). This system enables the issuance of appropriate health advisories based on the severity of pollution levels. The AQEWS is operational for Delhi-NCR and several other Indian cities.
Document names used: India_Health_Advisory_Air_Pollution.pdf
2026-02-22 15:42:44,064 - __main__ - INFO - data_and_intelligence_server.py:39 - RAG tool execution completed.
2026-02-22 15:42:51,802 - backoff - INFO - _common.py:105 - Backing off send_request(...) for 0.1s (requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Read timed out. (read timeout=15))
2026-02-22 15:46:51,084 - __main__ - INFO - data_and_intelligence_server.py:17 - Starting data analysis with query: Calculate the mean, median, and percentiles of humidity from the environmental data. Please save the results to the shared folder.
2026-02-22 15:46:51,084 - tool_utilities.data_analysis_agent - INFO - data_analysis_agent.py:23 - Invoking data_analysis_agent with query: Calculate the mean, median, and percentiles of humidity from the environmental data. Please save the results to the shared folder. and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\19\3 and csv filename: New York City_2026-01-11_2026-01-17_762e9531-2dc0-45e6-b056-57351959f70a.csv
2026-02-22 15:46:51,087 - tool_utilities.data_analysis_agent - INFO - data_analysis_agent.py:36 - CSV file found at path: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\19\1\New York City_2026-01-11_2026-01-17_762e9531-2dc0-45e6-b056-57351959f70a.csv
2026-02-22 15:46:51,553 - google_genai._api_client - INFO - before_sleep.py:64 - Retrying google.genai._api_client.BaseApiClient._request_once in 1.84 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 8.558253665s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}.
2026-02-22 15:46:53,490 - google_genai._api_client - INFO - before_sleep.py:64 - Retrying google.genai._api_client.BaseApiClient._request_once in 2.75 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 6.620191283s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '6s'}]}}.
2026-02-22 15:46:56,347 - google_genai._api_client - INFO - before_sleep.py:64 - Retrying google.genai._api_client.BaseApiClient._request_once in 4.2 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 3.756203577s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '3s'}]}}.
2026-02-22 15:47:00,702 - google_genai._api_client - INFO - before_sleep.py:64 - Retrying google.genai._api_client.BaseApiClient._request_once in 8.34 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 59.450361578s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '59s'}]}}.
2026-02-22 15:47:09,527 - google_genai._api_client - INFO - before_sleep.py:64 - Retrying google.genai._api_client.BaseApiClient._request_once in 16 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 50.570291697s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '50s'}]}}.
2026-02-22 15:47:25,803 - tool_utilities.data_analysis_agent - ERROR - data_analysis_agent.py:77 - Error in data_analysis_agent invoke method: Error calling model 'gemini-2.5-flash-lite' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 34.293759341s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '34s'}]}}
2026-02-22 15:47:25,813 - __main__ - INFO - data_and_intelligence_server.py:19 - Data analysis completed.
2026-02-23 08:43:42,248 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:219 - Use pytorch device_name: cpu
2026-02-23 08:43:42,254 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:227 - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-23 08:43:57,158 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:1710 - Save model to C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\models\all-MiniLM-L6-v2
2026-02-23 08:44:04,546 - sentence_transformers.cross_encoder.CrossEncoder - INFO - CrossEncoder.py:228 - Use pytorch device: cpu
2026-02-23 08:44:05,328 - sentence_transformers.cross_encoder.CrossEncoder - INFO - CrossEncoder.py:851 - Save model to C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\models\cross-encoder-ms-marco-MiniLM-L-6-v2
2026-02-23 08:44:07,691 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:227 - Load pretrained SentenceTransformer: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\models\all-MiniLM-L6-v2
2026-02-23 08:44:09,229 - sentence_transformers.cross_encoder.CrossEncoder - INFO - CrossEncoder.py:228 - Use pytorch device: cpu
2026-02-23 08:44:09,494 - chromadb.telemetry.product.posthog - INFO - posthog.py:22 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-23 09:14:53,224 - __main__ - INFO - data_and_intelligence_server.py:27 - Starting data visualization with User query: Plot the humidity trend for new york city from 2026-01-01 to 2026-01-11, CSV Filename: new_york_city_environmental_data_2026-01-01_to_2026-01-11.csv, Shared Folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_MATERIALS\PROJECTS\MCP_AGENTIC_AI\static\1\20\1
2026-02-23 09:14:53,231 - tool_utilities.plotting_agent - INFO - plotting_agent.py:27 - Invoking plotting_agent with query: Plot the humidity trend for new york city from 2026-01-01 to 2026-01-11 and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_MATERIALS\PROJECTS\MCP_AGENTIC_AI\static\1\20\1 and csv filename: new_york_city_environmental_data_2026-01-01_to_2026-01-11.csv
2026-02-23 09:14:53,243 - tool_utilities.plotting_agent - ERROR - plotting_agent.py:62 - CSV file new_york_city_environmental_data_2026-01-01_to_2026-01-11.csv not found in shared folder or parent directory.
2026-02-23 09:14:53,247 - __main__ - INFO - data_and_intelligence_server.py:29 - Data visualization completed.
2026-02-23 14:54:43,911 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:219 - Use pytorch device_name: cpu
2026-02-23 14:54:43,926 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:227 - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-23 14:54:53,088 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:1710 - Save model to C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\models\all-MiniLM-L6-v2
2026-02-23 14:54:59,617 - sentence_transformers.cross_encoder.CrossEncoder - INFO - CrossEncoder.py:228 - Use pytorch device: cpu
2026-02-23 14:55:00,236 - sentence_transformers.cross_encoder.CrossEncoder - INFO - CrossEncoder.py:851 - Save model to C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\models\cross-encoder-ms-marco-MiniLM-L-6-v2
2026-02-23 14:55:03,280 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:227 - Load pretrained SentenceTransformer: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\models\all-MiniLM-L6-v2
2026-02-23 14:55:04,622 - sentence_transformers.cross_encoder.CrossEncoder - INFO - CrossEncoder.py:228 - Use pytorch device: cpu
2026-02-23 14:55:04,827 - chromadb.telemetry.product.posthog - INFO - posthog.py:22 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-23 15:05:54,089 - __main__ - INFO - data_and_intelligence_server.py:27 - Starting data visualization with User query: Plot the humidity trend, CSV Filename: environmental_data_new_york_city_2026-01-01_to_2026-01-11.csv, Shared Folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\21\1
2026-02-23 15:05:54,117 - tool_utilities.plotting_agent - INFO - plotting_agent.py:29 - Invoking plotting_agent with query: Plot the humidity trend and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\21\1 and csv filename: environmental_data_new_york_city_2026-01-01_to_2026-01-11.csv
2026-02-23 15:05:54,133 - tool_utilities.plotting_agent - INFO - plotting_agent.py:40 - CSV not found in shared folder. Searching parent recursively...
2026-02-23 15:05:54,156 - tool_utilities.plotting_agent - ERROR - plotting_agent.py:62 - No CSV files found under parent directory: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\21
2026-02-23 15:05:54,167 - __main__ - INFO - data_and_intelligence_server.py:29 - Data visualization completed.
2026-02-23 15:25:22,542 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:227 - Load pretrained SentenceTransformer: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\models\all-MiniLM-L6-v2
2026-02-23 15:25:24,892 - sentence_transformers.cross_encoder.CrossEncoder - INFO - CrossEncoder.py:228 - Use pytorch device: cpu
2026-02-23 15:25:25,111 - chromadb.telemetry.product.posthog - INFO - posthog.py:22 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-23 15:35:49,071 - __main__ - INFO - data_and_intelligence_server.py:27 - Starting data visualization with User query: Plot the humidity trend for New York City from Jan 1 to Jan 11 2026, CSV Filename: humidity_trend_NYC_2026-01-01_to_2026-01-11.csv, Shared Folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\23\1
2026-02-23 15:35:49,085 - tool_utilities.plotting_agent - INFO - plotting_agent.py:29 - Invoking plotting_agent with query: Plot the humidity trend for New York City from Jan 1 to Jan 11 2026 and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\23\1 and csv filename: humidity_trend_NYC_2026-01-01_to_2026-01-11.csv
2026-02-23 15:35:49,113 - tool_utilities.plotting_agent - ERROR - plotting_agent.py:66 - No CSV files found under parent directory: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\23
2026-02-23 15:35:49,121 - __main__ - INFO - data_and_intelligence_server.py:29 - Data visualization completed.
2026-02-23 15:56:20,307 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:227 - Load pretrained SentenceTransformer: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\models\all-MiniLM-L6-v2
2026-02-23 15:56:24,806 - sentence_transformers.cross_encoder.CrossEncoder - INFO - CrossEncoder.py:228 - Use pytorch device: cpu
2026-02-23 15:56:25,226 - chromadb.telemetry.product.posthog - INFO - posthog.py:22 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-23 16:06:11,138 - __main__ - INFO - data_and_intelligence_server.py:29 - Starting data visualization with User query: Plot humidity trend, CSV Filename: humidity_trend_new_york_city_2026-01-01_to_2026-01-11.csv, Chat Session ID: 25, Chat ID: 1
2026-02-23 16:06:11,148 - tool_utilities.plotting_agent - INFO - plotting_agent.py:30 - Invoking plotting_agent with query: Plot humidity trend and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\25\1 and csv filename: humidity_trend_new_york_city_2026-01-01_to_2026-01-11.csv
2026-02-23 16:06:11,179 - tool_utilities.plotting_agent - ERROR - plotting_agent.py:64 - No CSV files found under parent directory: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\25
2026-02-23 16:06:11,182 - __main__ - INFO - data_and_intelligence_server.py:31 - Data visualization completed.
2026-02-23 16:35:54,697 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:227 - Load pretrained SentenceTransformer: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\servers\SERVER_A\tool_utilities\models\all-MiniLM-L6-v2
2026-02-23 16:35:55,284 - sentence_transformers.cross_encoder.CrossEncoder - INFO - CrossEncoder.py:228 - Use pytorch device: cpu
2026-02-23 16:35:55,370 - chromadb.telemetry.product.posthog - INFO - posthog.py:22 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2026-02-23 16:44:46,495 - __main__ - INFO - data_and_intelligence_server.py:29 - Starting data visualization with User query: Plot the humidity trend for new york city from 2026-01-01 to 2026-01-11, CSV Filename: new_york_city_environmental_data_2026-01-01_to_2026-01-11.csv, Chat Session ID: 27, Chat ID: 1
2026-02-23 16:44:46,505 - tool_utilities.plotting_agent - INFO - plotting_agent.py:30 - Invoking plotting_agent with query: Plot the humidity trend for new york city from 2026-01-01 to 2026-01-11 and shared folder: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\27\1 and csv filename: new_york_city_environmental_data_2026-01-01_to_2026-01-11.csv
2026-02-23 16:44:46,532 - tool_utilities.plotting_agent - ERROR - plotting_agent.py:64 - No CSV files found under parent directory: C:\Users\soundarya.sarathi\OneDrive - Accenture\study_materials\PROJECTS\MCP_AGENTIC_AI\static\1\27
2026-02-23 16:44:46,544 - __main__ - INFO - data_and_intelligence_server.py:31 - Data visualization completed.
